[{"content":"现版本存在的问题 目前在生产环境中部署的旧版本Redis存在的问题：\n大 key 过期删除引发集群节点阻塞失去响应不可用； 内存碎片高，内存使用率低； 运维时，手动主从切换总会产生复制风暴问题，主从无法同步； bgsave 内存消耗较高，有 OOM 风险。 推进版本升级 由于以上原因，开始推进 Redis 版本升级。\n版本升级工作流程：\n通过文档与源码，调研 Redis 新特性； 客户端兼容性改造； 功能测试、性能测试和稳定性测试； 开发配套监控和运维工具； 推进上线。 ","permalink":"https://fullzsy.github.io/posts/tech/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/","summary":"记录Redis升级流程。","title":"Redis升级——开篇"},{"content":"自 Redis 4 版本引入了异步删除方法 unlink，官方对该接口的解释：\n“This command is very similar to DEL: it removes the specified keys. Just like DEL a key is ignored if it does not exist. However the command performs the actual memory reclaiming in a different thread, so it is not blocking, while DEL is. This is where the command name comes from: the command just unlinks the keys from the keyspace. The actual removal will happen later asynchronously.”\n可知 unlink 与 del 用法相同，只不过内存回收在另一个不同线程中，内存回收操作在 unlink 方法调用结束之后，因此是非阻塞方法。\n源码分析 异步删除流程 同步删除与异步删除的方法入口分别为 delCommand 方法与 unlinkCommand 方法。\nvoid delCommand(client *c) { delGenericCommand(c,server.lazyfree_lazy_user_del); } void unlinkCommand(client *c) { delGenericCommand(c,1); } 这两个方法都调用 delGenericCommand 方法，server.lazyfree_lazy_user_del 可通过配置文件配置，配置后可以使 del 命令与 unlink 命令完全相同。\n/* This command implements DEL and LAZYDEL. */ void delGenericCommand(client *c, int lazy) { int numdel = 0, j; for (j = 1; j \u0026lt; c-\u0026gt;argc; j++) { expireIfNeeded(c-\u0026gt;db,c-\u0026gt;argv[j],0); // 判断传入的 lazy 值选择异步删除或同步删除 int deleted = lazy ? dbAsyncDelete(c-\u0026gt;db,c-\u0026gt;argv[j]) : dbSyncDelete(c-\u0026gt;db,c-\u0026gt;argv[j]); if (deleted) { signalModifiedKey(c,c-\u0026gt;db,c-\u0026gt;argv[j]); notifyKeyspaceEvent(NOTIFY_GENERIC, \u0026#34;del\u0026#34;,c-\u0026gt;argv[j],c-\u0026gt;db-\u0026gt;id); server.dirty++; numdel++; } } addReplyLongLong(c,numdel); } delGenericCommand 方法判断传入的 lazy 参数值决定异步删除或者同步删除。\n/* Delete a key, value, and associated expiration entry if any, from the DB */ int dbSyncDelete(redisDb *db, robj *key) { return dbGenericDelete(db, key, 0); } /* Delete a key, value, and associated expiration entry if any, from the DB. If * the value consists of many allocations, it may be freed asynchronously. */ int dbAsyncDelete(redisDb *db, robj *key) { return dbGenericDelete(db, key, 1); } 同步删除和异步删除都是调用 dbGenericDelete 方法，仅传入的 async 参数不同。\n/* Helper for sync and async delete. */ static int dbGenericDelete(redisDb *db, robj *key, int async) { /* Deleting an entry from the expires dict will not free the sds of * the key, because it is shared with the main dictionary. */ // 删除 expires 字典中该 key，但不会删除 SDS 结构，因为该 SDS 在 dict 字典中被共享。 if (dictSize(db-\u0026gt;expires) \u0026gt; 0) dictDelete(db-\u0026gt;expires,key-\u0026gt;ptr); // 数据库字典中移除 key，不释放内存。 dictEntry *de = dictUnlink(db-\u0026gt;dict,key-\u0026gt;ptr); if (de) { robj *val = dictGetVal(de); /* Tells the module that the key has been unlinked from the database. */ moduleNotifyKeyUnlink(key,val,db-\u0026gt;id); /* We want to try to unblock any client using a blocking XREADGROUP */ if (val-\u0026gt;type == OBJ_STREAM) signalKeyAsReady(db,key,val-\u0026gt;type); if (async) { // 异步释放内存 freeObjAsync(key, val, db-\u0026gt;id); dictSetVal(db-\u0026gt;dict, de, NULL); } if (server.cluster_enabled) slotToKeyDelEntry(de, db); // 释放内存 dictFreeUnlinkedEntry(db-\u0026gt;dict,de); return 1; } else { return 0; } } /* You need to call this function to really free the entry after a call * to dictUnlink(). It\u0026#39;s safe to call this function with \u0026#39;he\u0026#39; = NULL. */ void dictFreeUnlinkedEntry(dict *d, dictEntry *he) { if (he == NULL) return; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } dbGenericDelete 方法首先将 key 在 expires 字典中删除并释放内存，再在 dict 字典中移除该 key，但此时不释放内存。 通过 async 参数判断是否需要异步释放内存，若需要则会调用 freeObjAsync 方法进行异步释放内存，若不需要异步释放内存，则在 dictFreeUnlinkedEntry 方法中直接释放。 若进入 freeObjAsync 方法但不满足异步释放条件（在 freeObjAsync 方法中），也会在 dictFreeUnlinkedEntry 方法中直接释放。\n/* If there are enough allocations to free the value object asynchronously, it * may be put into a lazy free list instead of being freed synchronously. The * lazy free list will be reclaimed in a different bio.c thread. If the value is * composed of a few allocations, to free in a lazy way is actually just * slower... So under a certain limit we just free the object synchronously. */ #define LAZYFREE_THRESHOLD 64 /* Free an object, if the object is huge enough, free it in async way. */ void freeObjAsync(robj *key, robj *obj, int dbid) { // 计算异步删除阈值 size_t free_effort = lazyfreeGetFreeEffort(key,obj,dbid); /* Note that if the object is shared, to reclaim it now it is not * possible. This rarely happens, however sometimes the implementation * of parts of the Redis core may call incrRefCount() to protect * objects, and then call dbDelete(). */ if (free_effort \u0026gt; LAZYFREE_THRESHOLD \u0026amp;\u0026amp; obj-\u0026gt;refcount == 1) { atomicIncr(lazyfree_objects,1); // 任务超过异步删除阈值，创建异步删除任务 bioCreateLazyFreeJob(lazyfreeFreeObject,1,obj); } else { decrRefCount(obj); } } 重点看 freeObjAsync 方法，先计算该 key 的异步删除阈值，若大于阈值 64，则为该 key 创建异步删除任务。\nvoid bioCreateLazyFreeJob(lazy_free_fn free_fn, int arg_count, ...) { va_list valist; /* Allocate memory for the job structure and all required * arguments */ bio_job *job = zmalloc(sizeof(*job) + sizeof(void *) * (arg_count)); job-\u0026gt;free_args.free_fn = free_fn; va_start(valist, arg_count); for (int i = 0; i \u0026lt; arg_count; i++) { job-\u0026gt;free_args.free_args[i] = va_arg(valist, void *); } va_end(valist); // 提交任务 bioSubmitJob(BIO_LAZY_FREE, job); } void bioSubmitJob(int type, bio_job *job) { // 互斥锁 pthread_mutex_lock(\u0026amp;bio_mutex[type]); // 添加任务至末尾 listAddNodeTail(bio_jobs[type],job); bio_pending[type]++; // 发送信号唤醒阻塞线程 pthread_cond_signal(\u0026amp;bio_newjob_cond[type]); pthread_mutex_unlock(\u0026amp;bio_mutex[type]); } bioCreateLazyFreeJob 方法创建任务并调用 bioSubmitJob 方法提交任务到 job 数据结构中。\nvoid *bioProcessBackgroundJobs(void *arg) { bio_job *job; unsigned long type = (unsigned long) arg; sigset_t sigset; /* Check that the type is within the right interval. */ if (type \u0026gt;= BIO_NUM_OPS) { serverLog(LL_WARNING, \u0026#34;Warning: bio thread started with wrong type %lu\u0026#34;,type); return NULL; } switch (type) { case BIO_CLOSE_FILE: redis_set_thread_title(\u0026#34;bio_close_file\u0026#34;); break; case BIO_AOF_FSYNC: redis_set_thread_title(\u0026#34;bio_aof_fsync\u0026#34;); break; case BIO_LAZY_FREE: redis_set_thread_title(\u0026#34;bio_lazy_free\u0026#34;); break; } redisSetCpuAffinity(server.bio_cpulist); makeThreadKillable(); pthread_mutex_lock(\u0026amp;bio_mutex[type]); /* Block SIGALRM so we are sure that only the main thread will * receive the watchdog signal. */ sigemptyset(\u0026amp;sigset); sigaddset(\u0026amp;sigset, SIGALRM); if (pthread_sigmask(SIG_BLOCK, \u0026amp;sigset, NULL)) serverLog(LL_WARNING, \u0026#34;Warning: can\u0026#39;t mask SIGALRM in bio.c thread: %s\u0026#34;, strerror(errno)); while(1) { listNode *ln; /* The loop always starts with the lock hold. */ if (listLength(bio_jobs[type]) == 0) { pthread_cond_wait(\u0026amp;bio_newjob_cond[type],\u0026amp;bio_mutex[type]); continue; } /* Pop the job from the queue. */ ln = listFirst(bio_jobs[type]); job = ln-\u0026gt;value; /* It is now possible to unlock the background system as we know have * a stand alone job structure to process.*/ pthread_mutex_unlock(\u0026amp;bio_mutex[type]); /* Process the job accordingly to its type. */ if (type == BIO_CLOSE_FILE) { if (job-\u0026gt;fd_args.need_fsync) { redis_fsync(job-\u0026gt;fd_args.fd); } close(job-\u0026gt;fd_args.fd); } else if (type == BIO_AOF_FSYNC) { /* The fd may be closed by main thread and reused for another * socket, pipe, or file. We just ignore these errno because * aof fsync did not really fail. */ if (redis_fsync(job-\u0026gt;fd_args.fd) == -1 \u0026amp;\u0026amp; errno != EBADF \u0026amp;\u0026amp; errno != EINVAL) { int last_status; atomicGet(server.aof_bio_fsync_status,last_status); atomicSet(server.aof_bio_fsync_status,C_ERR); atomicSet(server.aof_bio_fsync_errno,errno); if (last_status == C_OK) { serverLog(LL_WARNING, \u0026#34;Fail to fsync the AOF file: %s\u0026#34;,strerror(errno)); } } else { atomicSet(server.aof_bio_fsync_status,C_OK); } } else if (type == BIO_LAZY_FREE) { job-\u0026gt;free_args.free_fn(job-\u0026gt;free_args.free_args); } else { serverPanic(\u0026#34;Wrong job type in bioProcessBackgroundJobs().\u0026#34;); } zfree(job); /* Lock again before reiterating the loop, if there are no longer * jobs to process we\u0026#39;ll block again in pthread_cond_wait(). */ pthread_mutex_lock(\u0026amp;bio_mutex[type]); listDelNode(bio_jobs[type],ln); bio_pending[type]--; /* Unblock threads blocked on bioWaitStepOfType() if any. */ pthread_cond_broadcast(\u0026amp;bio_step_cond[type]); } } 执行后台任务方法 bioProcessBackgroundJobs，详细过程不在讨论的主题中。\n结论：异步删除能够解决主线程阻塞问题。\n惰性删除与异步删除 Redis 惰性删除策略是否采用异步删除策略？\n在惰性删除中，Redis 在操作 Key 时会先判断该 Key 是否过期，若过期则会删除该 Key。\n/* This function is called when we are going to perform some operation * in a given key, but such key may be already logically expired even if * it still exists in the database. The main way this function is called * is via lookupKey*() family of functions. * * The behavior of the function depends on the replication role of the * instance, because by default replicas do not delete expired keys. They * wait for DELs from the master for consistency matters. However even * replicas will try to have a coherent return value for the function, * so that read commands executed in the replica side will be able to * behave like if the key is expired even if still present (because the * master has yet to propagate the DEL). * * In masters as a side effect of finding a key which is expired, such * key will be evicted from the database. Also this may trigger the * propagation of a DEL/UNLINK command in AOF / replication stream. * * On replicas, this function does not delete expired keys by default, but * it still returns 1 if the key is logically expired. To force deletion * of logically expired keys even on replicas, use the EXPIRE_FORCE_DELETE_EXPIRED * flag. Note though that if the current client is executing * replicated commands from the master, keys are never considered expired. * * On the other hand, if you just want expiration check, but need to avoid * the actual key deletion and propagation of the deletion, use the * EXPIRE_AVOID_DELETE_EXPIRED flag. * * The return value of the function is 0 if the key is still valid, * otherwise the function returns 1 if the key is expired. */ int expireIfNeeded(redisDb *db, robj *key, int flags) { if (!keyIsExpired(db,key)) return 0; /* If we are running in the context of a replica, instead of * evicting the expired key from the database, we return ASAP: * the replica key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. The * exception is when write operations are performed on writable * replicas. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. * * When replicating commands from the master, keys are never considered * expired. */ if (server.masterhost != NULL) { if (server.current_client == server.master) return 0; if (!(flags \u0026amp; EXPIRE_FORCE_DELETE_EXPIRED)) return 1; } /* In some cases we\u0026#39;re explicitly instructed to return an indication of a * missing key without actually deleting it, even on masters. */ if (flags \u0026amp; EXPIRE_AVOID_DELETE_EXPIRED) return 1; /* If clients are paused, we keep the current dataset constant, * but return to the client what we believe is the right state. Typically, * at the end of the pause we will properly expire the key OR we will * have failed over and the new primary will send us the expire. */ if (checkClientPauseTimeoutAndReturnIfPaused()) return 1; /* Delete the key */ // 删除 key deleteExpiredKeyAndPropagate(db,key); return 1; } expireIfNeeded 方法会调用 deleteExpiredKeyAndPropagate 方法删除 key。\n删除 key 时会读取 server.lazyfree_lazy_expire 配置决定删除策略。server.lazyfree_lazy_expire 可在配置文件中配置，配置后惰性删除将采用异步删除策略。\n/* Delete the specified expired key and propagate expire. */ void deleteExpiredKeyAndPropagate(redisDb *db, robj *keyobj) { mstime_t expire_latency; latencyStartMonitor(expire_latency); if (server.lazyfree_lazy_expire) // 采用异步删除策略 dbAsyncDelete(db,keyobj); else dbSyncDelete(db,keyobj); latencyEndMonitor(expire_latency); latencyAddSampleIfNeeded(\u0026#34;expire-del\u0026#34;,expire_latency); notifyKeyspaceEvent(NOTIFY_EXPIRED,\u0026#34;expired\u0026#34;,keyobj,db-\u0026gt;id); signalModifiedKey(NULL, db, keyobj); propagateDeletion(db,keyobj,server.lazyfree_lazy_expire); server.stat_expiredkeys++; } 结论：Redis 惰性删除在配置后可采用异步删除策略。\n定时删除与异步删除 定时任务 serverCron 方法最终会调用 activeExpireCycleTryExpire 方法，该方法仍会调用 deleteExpiredKeyAndPropagate 方法。\n/* Helper function for the activeExpireCycle() function. * This function will try to expire the key that is stored in the hash table * entry \u0026#39;de\u0026#39; of the \u0026#39;expires\u0026#39; hash table of a Redis database. * * If the key is found to be expired, it is removed from the database and * 1 is returned. Otherwise no operation is performed and 0 is returned. * * When a key is expired, server.stat_expiredkeys is incremented. * * The parameter \u0026#39;now\u0026#39; is the current time in milliseconds as is passed * to the function to avoid too many gettimeofday() syscalls. */ int activeExpireCycleTryExpire(redisDb *db, dictEntry *de, long long now) { long long t = dictGetSignedIntegerVal(de); if (now \u0026gt; t) { sds key = dictGetKey(de); robj *keyobj = createStringObject(key,sdslen(key)); // 删除 key deleteExpiredKeyAndPropagate(db,keyobj); decrRefCount(keyobj); return 1; } else { return 0; } } 结论：Redis 定时删除在配置后可采用异步删除策略。\n结论 异步删除策略能够在删除大 Key 时避免主线程阻塞，惰性删除与定时删除在配置后均可采用异步删除策略，因此异步删除能够解决大 Key 过期引起的主线程阻塞问题。\n","permalink":"https://fullzsy.github.io/posts/tech/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/","summary":"通过分析 Redis 异步删除源码，判断异步删除能否解决大 Key 过期阻塞主线程的问题。","title":"Redis异步删除解决大Key过期阻塞问题可行性分析"},{"content":"前提条件 查找的数组是有序的。\n递归写法 public class BinarySearch { public static int rank(int key, int[] a) { return rank(key, a, 0, a.length - 1); } public static int rank(int key, int[] a, int lo, int hi) { if (lo \u0026gt; hi) return -1; int mid = lo + (hi - lo) / 2; if (key \u0026lt; a[mid]) return rank(key, a, lo, hi - 1); else if (key \u0026gt; a[mid]) return rank(key, a, lo + 1, hi); else return mid; } } 循环写法 public class BinarySearch { public static int rank(int key, int[] a) { int lo = 0; int hi = a.length - 1; while (lo \u0026lt; hi) { int mid = lo + (hi - lo) / 2; if (key \u0026lt; a[mid]) hi = lo - 1; else if (key \u0026gt; a[mid]) lo = hi + 1; else return mid; } return -1; } } ","permalink":"https://fullzsy.github.io/posts/read/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","summary":"《算法第四版》二分查找","title":"《算法第四版》二分查找"},{"content":"自然语言描述 计算两个非负整数 p 和 q 的最大公约数：若 q 是 0，则最大公约数为 p。否则，将 p 除以 q 得到余数 r，p 和 q 的最大公约数即为 q 和 r 的最大公约数。\n递归写法 public class Euclid { public static int gcd(int p, int q) { if (q == 0) return p; int r = p % q; return gcd(q, r); } } 循环写法 public class Euclid { public static int gcd(int p, int q) { if (q == 0) return p; while (q != 0) { int r = p % q; p = q; q = r; } return p; } } ","permalink":"https://fullzsy.github.io/posts/read/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/","summary":"《算法第四版》欧几里得算法求最大公因数","title":"《算法第四版》欧几里得算法求最大公因数"},{"content":"本系列文章作用 2023 年计划将《算法第四版》认真阅读一遍，在博客中整理常用的算法，把书读薄，时常复习，提高编码水平。\n习题仓库：https://github.com/FullZSY/algs4\n加油！\n","permalink":"https://fullzsy.github.io/posts/read/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_00_%E9%98%85%E8%AF%BB%E5%BC%80%E7%AF%87/","summary":"《算法第四版》阅读总结","title":"《算法第四版》阅读"},{"content":"关于我 姓名: Shuyang 职业: 后端程序员，负责 Redis 相关工作 ","permalink":"https://fullzsy.github.io/about/","summary":"关于我 姓名: Shuyang 职业: 后端程序员，负责 Redis 相关工作 ","title":"🙋🏻‍♂️关于"}]