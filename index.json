[{"categories":["「算法第四版」"],"content":"选择排序、插入排序和希尔排序","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"categories":["「算法第四版」"],"content":" 排序算法类的模版 public class Sort { public static void sort(Comparable[] a) { // 排序算法具体实现 } private static boolean less(Comparable v, Comparable w) { return v.compareTo(w) \u003c 0; } private static void exch(Comparable[] a, int i, int j) { Comparable temp = a[i]; a[i] = a[j]; a[j] = temp; } private static void show(Comparable[] a) { for (int i = 0; i \u003c a.length; i++) StdOut.print(a[i] + \" \"); StdOut.println(); } private static boolean isSorted(Comparable[] a) { for (int i = 1; i \u003c a.length; i++) { if (less(a[i], a[i - 1])) return false; } return true; } } ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#排序算法类的模版"},{"categories":["「算法第四版」"],"content":" 选择排序","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#选择排序"},{"categories":["「算法第四版」"],"content":" 选择排序算法描述首先，找到数组中最小的元素，其次，将它和数组的第一个元素交换位置。再次，在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。直到将整个数组排序。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:2:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#选择排序算法描述"},{"categories":["「算法第四版」"],"content":" 选择排序的实现 public class Selection { public static void sort(Comparable[] a) { int n = a.length; for (int i = 0; i \u003c n; i++) { int min = i; for (int j = i + 1; j \u003c n; j++) { if (less(a[j], a[min])) min = j; } exch(a, i, min); assert isSorted(a, 0, i); } assert isSorted(a); } } 算法将第 i 小的元素放到 a[i] 中。数组的第 i 个位置的左边是 i 个最小的元素且它们不会再被访问。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:2:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#选择排序的实现"},{"categories":["「算法第四版」"],"content":" 选择排序的特点对于长度为 N 的数组，选择排序需要大约 (N^2) / 2 次比较和 N 次交换。 运行时间和输入无关。 数据移动是最少的。数据移动与数组长度线性相关。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:2:3","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#选择排序的特点"},{"categories":["「算法第四版」"],"content":" 插入排序","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#插入排序"},{"categories":["「算法第四版」"],"content":" 插入排序算法描述初始状态，把第一个元素看做只有一个元素的有序序列，从第二个元素开始及其之后的元素是未排序序列。对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:3:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#插入排序算法描述"},{"categories":["「算法第四版」"],"content":" 插入排序的实现 public class Insertion { public static void sort(Comparable[] a) { int n = a.length; for (int i = 1; i \u003c n; i++) { for (int j = i; j \u003e 0 \u0026\u0026 less(a[j], a[j - 1]); j--) { exch(a, j, j - 1); } assert isSorted(a, 0, i); } assert isSorted(a); } public static void sort(Comparable[] a, int lo, int hi) { for (int i = lo + 1; i \u003c hi; i++) { for (int j = i; j \u003e lo \u0026\u0026 less(a[j], a[j - 1]); j--) { exch(a, j, j - 1); } } assert isSorted(a, lo, hi); } } 对于 1 到 N - 1 之间的每个 i，将 a[i] 与 a[0] 到 a[i - 1] 中比它小的所有元素依次有序地交换。在索引 i 由左向右变化的过程中，它左侧的元素总是有序的，当 i 到达数组右端时完成排序。 在内循环中将较大的元素都向右移动而不总是交换两个元素，可以大幅提高插入排序的速度。 public class InsertionSortWithoutExchange { public static void sort(Comparable[] a) { int n = a.length; for (int i = 1; i \u003c n; i++) { Comparable value = a[i]; int j; for (j = i; j \u003e 0 \u0026\u0026 less(value, a[j - 1]); j--) { a[j] = a[j - 1]; } a[j] = value; } assert isSorted(a, 0, n - 1); } } 先找出最小的元素并将其置于数组的最左边，这样能够规避判断边界条件 j \u003e 0 从而提高插入排序速度，这个元素被称为哨兵。 public class InsertionWithSentinel { public static void sort(Comparable[] a) { int min = 0; for (int i = 1; i \u003c a.length; i++) if (less(a[i], a[min])) min = i; exch(a, 0, min); for (int i = 2; i \u003c a.length; i++) { for (int j = i; less(j, j - 1); j--) { exch(a, j, j - 1); } } } } ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:3:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#插入排序的实现"},{"categories":["「算法第四版」"],"content":" 插入排序的特点对于随机排列的长度为 N 且逐渐不重复的数组，平均情况下插入排序需要 ~(N^2)/4 次比较与交换。最坏情况下需要 ~(N^2)/2 次比较与交换。最好情况下需要 N - 1 次比较和 0 次交换。 插入排序所需时间取决于元素的初始顺序。因此插入排序适合实际应用中部分有序的非随机数组。 插入排序的比较和交换的次数相等。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:3:3","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#插入排序的特点"},{"categories":["「算法第四版」"],"content":" 希尔排序","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:4:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#希尔排序"},{"categories":["「算法第四版」"],"content":" 希尔排序算法描述希尔排序是更高效的插入排序。 对于大规模乱序数组插入排序很慢，因为它只会交换相邻的元素，因此元素只能一点一点地从数维的一端移动到另一端。 希尔排序使数组中任意间隔为 h 的元素都是有序的。这样的数组被称为 h 有序数组。在进行排序时，如果 h 很大，我们就能将元素移动到很远的地方，为实现更小的 h 有序创造方便。对于任意以 1 结尾的 h 序列，我们都能够将数组排序。这就是希尔排序。 希尔排序比插入排序更高效的原因：排序之初，各个子数组都很短，排序之后子数组都是部分有序的，这两种情况都很适合插入排序。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:4:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#希尔排序算法描述"},{"categories":["「算法第四版」"],"content":" 希尔排序的实现递增序列为 (3^k - 1) / 2 的希尔排序。 public class Shell { public static void sort(Comparable[] a) { int n = a.length; // 3x+1 increment sequence: 1, 4, 13, 40, 121, 364, 1093, ... int h = 1; while (h \u003c n / 3) h = 3 * h + 1; while (h \u003e= 1) { // h-sort the array for (int i = h; i \u003c n; i++) { for (int j = i; j \u003e= h \u0026\u0026 less(a[j], a[j - h]); j -= h) { exch(a, j, j - h); } } assert isHsorted(a, h); h /= 3; } assert isSorted(a); } // is the array h-sorted? private static boolean isHsorted(Comparable[] a, int h) { for (int i = h; i \u003c a.length; i++) if (less(a[i], a[i - h])) return false; return true; } } 也可以将希尔排序的递增序列存储在一个数组中。 class ShellSortKeepIncrementSequence { public static void sort(Comparable[] a) { int n = a.length; int[] incrementSequence = getIncrementSequence(n); for (int h : incrementSequence) { for (int i = h; i \u003c n; i++) { for (int j = i; j \u003e= h \u0026\u0026 less(a[j], a[j - h]); j -= h) { exch(a, j, j - h); } } } } private static int[] getIncrementSequence(int n) { int size = (int) (Math.log(2 * n + 1) / Math.log(3)); int[] incrementSequence = new int[size]; for (int h = 0, i = size - 1; i \u003e= 0; i--) { h = 3 * h + 1; incrementSequence[i] = h; } return incrementSequence; } } 一个更加高效的递增序列为 1，5，19，41, 109，209，505，929，2161，3905，8929，16 001，36 289，64 769，146 305，260 609。该序列通过 9 * (4^k) - 9 * (2^k) + 1 与 (4^k) - 3 * (2^k) + 1 综合得到 。在实际应用中可能可以将性能改进 20% ~ 40%。 class ShellSortHighPerformanceIncrementSequence { public static void sort(Comparable[] a) { int n = a.length; Stack\u003cInteger\u003e incrementSequence = getIncrementSequence(n); while (!incrementSequence.isEmpty()) { int h = incrementSequence.pop(); for (int i = h; i \u003c n; i++) { for (int j = i; j \u003e= h \u0026\u0026 less(a[j], a[j - h]); j -= h) { exch(a, j, j - h); } } } } private static Stack\u003cInteger\u003e getIncrementSequence(int n) { Stack\u003cInteger\u003e sequence = new Stack\u003c\u003e(); int value = -1; int k = 0; while (true) { value = (int) (9 * Math.pow(4, k) - 9 * Math.pow(2, k) + 1); if (value \u003c n) sequence.push(value); value = (int) (Math.pow(4, k + 2) - 3 * Math.pow(2, k + 2) + 1); if (value \u003c n) sequence.push(value); if (value \u003e= n) break; k++; } return sequence; } } ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:4:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#希尔排序的实现"},{"categories":["「算法第四版」"],"content":" 希尔排序的特点希尔排序比插入排序和选择排序要快得多，并且数组越大，优势越大。 对于中等大小的数组它的运行时间是可以接受的。它的代码量很小，且不需要使用额外的内存空间。 解决一个排序问题时，可以先用希尔排序，然后再考虑是否值得将它替换为更加复杂的排序算法。 ","date":"2023-04-20","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:4:3","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」","排序算法"],"title":"「算法第四版」初级排序算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_06_%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#希尔排序的特点"},{"categories":["Redis升级"],"content":"分析 Redis 内存碎片整理功能，给出控制内存碎片可行方案。","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/"},{"categories":["Redis升级"],"content":" 内存碎片产生原因内存碎片产生有两种原因 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:1:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片产生原因"},{"categories":["Redis升级"],"content":" 内存分配原因 To store user keys, Redis allocates at most as much memory as the maxmemory setting enables (however there are small extra allocations possible). Redis 在分配内存时有可能会分配少量额外空间。 Redis 封装的 zmalloc 方法会调用 ztrymalloc_usable 方法额外分配 PREFIX_SIZE 大小的空间。 /* Try allocating memory, and return NULL if failed. * '*usable' is set to the usable size if non NULL. */ void *ztrymalloc_usable(size_t size, size_t *usable) { /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */ if (size \u003e= SIZE_MAX/2) return NULL; void *ptr = malloc(MALLOC_MIN_SIZE(size)+PREFIX_SIZE); if (!ptr) return NULL; #ifdef HAVE_MALLOC_SIZE size = zmalloc_size(ptr); update_zmalloc_stat_alloc(size); if (usable) *usable = size; return ptr; #else *((size_t*)ptr) = size; update_zmalloc_stat_alloc(size+PREFIX_SIZE); if (usable) *usable = size; return (char*)ptr+PREFIX_SIZE; #endif } 其次在默认内存分配器 Jemalloc 下，会按照固定大小分配内存，比如需要申请 6 bytes，但实际分配 8 bytes。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:1:1","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存分配原因"},{"categories":["Redis升级"],"content":" 频繁修改 Redis 中数据 Redis will not always free up (return) memory to the OS when keys are removed. This is not something special about Redis, but it is how most malloc() implementations work. For example if you fill an instance with 5GB worth of data, and then remove the equivalent of 2GB of data, the Resident Set Size (also known as the RSS, which is the number of memory pages consumed by the process) will probably still be around 5GB, even if Redis will claim that the user memory is around 3GB. This happens because the underlying allocator can’t easily release the memory. For example often most of the removed keys were allocated in the same pages as the other keys that still exist. 在删除数据时，Redis 不会直接将该部分内存归还操作系统，原因是有可能有其他数据落在相同页上，这部分删除的内存也会产生内存碎片。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:1:2","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#频繁修改-redis-中数据"},{"categories":["Redis升级"],"content":" 内存碎片率mem_fragmentation_ratio = used_memory_rss / used_memory 可以理解为 Redis 向操作系统申请的内存与 Redis 实际使用内存的比。 理想情况下内存碎片率维持在 1.03 最好。正常情况下在 1-1.5 之间。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:2:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片率"},{"categories":["Redis升级"],"content":" 内存碎片整理功能默认配置 activedefrag = 0 # 内存碎片整理总开关，默认不开启。 active-defrag-cycle-min = 1 # 内存碎片整理的 CPU 时间占总 CPU 时间不低于 1%。 active-defrag-cycle-max = 25 # 内存碎片整理的 CPU 时间占总 CPU 时间不高于 25%。 active-defrag-threshold-lower = 10 # 内存碎片率小于 10%，不进行内存碎片整理。 active-defrag-threshold-upper = 100 # 在 100% 碎片率时达到最大的碎片整理力度。 active-defrag-max-scan-fields = 1000 # key 中包含的 field 大于 1000 会被单独处理。 active-defrag-ignore-bytes = 100mb # 碎片总空间少于 100mb 不进行内存整理。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:3:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片整理功能默认配置"},{"categories":["Redis升级"],"content":" 内存碎片整理的实现内存碎片整理功能通过 activeDefragCycle 函数实现，该函数通过 serverCron 函数调用，在开启该功能后会被定时调用。一次完整的内存碎片整理过程需要多次调用 activeDefragCycle 函数，即会横跨多次定时任务。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:4:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片整理的实现"},{"categories":["Redis升级"],"content":" 控制占用 CPU 时间比率限制的实现通过 active-defrag-cycle-min、active-defrag-cycle-max、active-defrag-threshold-lower、active-defrag-threshold-upper 四个配置能够控制内存碎片整理功能占用 CPU 时间的百分比。 该百分比最终会被计算为每次执行 activeDefragCycle 函数的最大时间限制 timeLimit，从而控制每次执行内存碎片整理功能的时间。 #define INTERPOLATE(x, x1, x2, y1, y2) ( (y1) + ((x)-(x1)) * ((y2)-(y1)) / ((x2)-(x1)) ) #define LIMIT(y, min, max) ((y)\u003c(min)? min: ((y)\u003e(max)? max: (y))) /* decide if defrag is needed, and at what CPU effort to invest in it */ void computeDefragCycles() { size_t frag_bytes; // 获得内存碎片率和内存碎片的总字节数 float frag_pct = getAllocatorFragmentation(\u0026frag_bytes); /* If we're not already running, and below the threshold, exit. */ // 如果当前未进行内存碎片整理，且内存碎片率和内存碎片总字节数不满足阈值要求，退出 if (!server.active_defrag_running) { if(frag_pct \u003c server.active_defrag_threshold_lower || frag_bytes \u003c server.active_defrag_ignore_bytes) return; } /* Calculate the adaptive aggressiveness of the defrag */ // 自适应计算内存碎片清理的 cpu 占用百分比 int cpu_pct = INTERPOLATE(frag_pct, server.active_defrag_threshold_lower, server.active_defrag_threshold_upper, server.active_defrag_cycle_min, server.active_defrag_cycle_max); // 将 cpu 占用百分比限制在 [active_defrag_cycle_min, active_defrag_cycle_max] cpu_pct = LIMIT(cpu_pct, server.active_defrag_cycle_min, server.active_defrag_cycle_max); /* We allow increasing the aggressiveness during a scan, but don't * reduce it. */ if (cpu_pct \u003e server.active_defrag_running) { // 记录比率 server.active_defrag_running = cpu_pct; serverLog(LL_VERBOSE, \"Starting active defrag, frag=%.0f%%, frag_bytes=%zu, cpu=%d%%\", frag_pct, frag_bytes, cpu_pct); } } 计算公式： cycle-min + (frag_pct - threshold_lower) * (cycle_max - cycle_min) / (threshold_upper - threshold_lower)。 若当前内存碎片率为 1.5，则计算出来的 cpu_pct = 14。 则 timelimit = 1000000 * server.active_defrag_running / server.hz / 100 = 1000000 * 14 / 10 / 100 = 14,000 μs = 14 ms。 该值计算出来后，会在每 16 次 scan，或每 512 次指针移动，或每 64 个 key 完成内存整理完毕后，判断运行时间是否超过运行时间限制，若超过则退出本次内存整理。 即在内存碎片率为 1.5 时，每次定时任务会花费 14ms 左右时间整理内存碎片。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:4:1","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#控制占用-cpu-时间比率限制的实现"},{"categories":["Redis升级"],"content":" 内存碎片整理核心实现内存整理功能通过 scan 键空间实现。每次 scan 时会调用 defragScanCallback 回调函数，执行 scan 出来的 key 的内存碎片清理工作。 cursor = dictScan(db-\u003edict, cursor, defragScanCallback, defragDictBucketCallback, db); defragScanCallback 调用 defragKey 函数，先尝试整理 key 对象，再判断 value 对象的编码从而调用相关函数整理 value 对象。 最终都会调用 activeDefragAlloc 函数进行内存整理。内存整理的过程为：分配新内存、内存复制、释放旧内存。 /* Defrag helper for generic allocations. * * returns NULL in case the allocation wasn't moved. * when it returns a non-null value, the old pointer was already released * and should NOT be accessed. */ void* activeDefragAlloc(void *ptr) { size_t size; void *newptr; if(!je_get_defrag_hint(ptr)) { server.stat_active_defrag_misses++; return NULL; } /* move this allocation to a new allocation. * make sure not to use the thread cache. so that we don't get back the same * pointers we try to free */ size = zmalloc_size(ptr); // 分配新内存 newptr = zmalloc_no_tcache(size); // 内存复制 memcpy(newptr, ptr, size); // 释放旧内存 zfree_no_tcache(ptr); return newptr; } 这样就完成了单个内存区域的内存整理。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:4:2","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片整理核心实现"},{"categories":["Redis升级"],"content":" 内存碎片整理大 Key 是否阻塞假设有一大 key 其拥有的元素为 fields 个。 在处理到该 key 时，会比较 fields 与 active-defrag-max-scan-fields 的大小，若 fields \u003e active-defrag-max-scan-fields，则将其标记为大 key 放在一个列表里，并跳过该 key 的内存整理。 if (dictSize(d) \u003e server.active_defrag_max_scan_fields) defragLater(db, kde); else defragged += activeDefragSdsDict(d, DEFRAG_SDS_DICT_VAL_IS_SDS); 在 scan 下一个桶之前，会检查列表里是否有大 key 未完成内存整理，若有则会单独为大 key 进行内存整理。 /* before scanning the next bucket, see if we have big keys left from the previous bucket to scan */ if (defragLaterStep(db, endtime)) { quit = 1; /* time is up, we didn't finish all the work */ break; /* this will exit the function and we'll continue on the next cycle */ } 在整理大 key 的内存时，也会分多次整理。会在每 16 次迭代，或每 512 个指针移动，或每 64 个 field 内存整理完毕后，判断运行时间是否超过运行时间限制，若超过则退出本次内存整理。 do { int quit = 0; if (defragLaterItem(de, \u0026defrag_later_cursor, endtime,db-\u003eid)) quit = 1; /* time is up, we didn't finish all the work */ /* Once in 16 scan iterations, 512 pointer reallocations, or 64 fields * (if we have a lot of pointers in one hash bucket, or rehashing), * check if we reached the time limit. */ if (quit || (++iterations \u003e 16 || server.stat_active_defrag_hits - prev_defragged \u003e 512 || server.stat_active_defrag_scanned - prev_scanned \u003e 64)) { if (quit || ustime() \u003e endtime) { if(key_defragged != server.stat_active_defrag_hits) server.stat_active_defrag_key_hits++; else server.stat_active_defrag_key_misses++; return 1; } iterations = 0; prev_defragged = server.stat_active_defrag_hits; prev_scanned = server.stat_active_defrag_scanned; } } while(defrag_later_cursor); 即一个大 key 的内存整理会分多次处理，不会长时间阻塞主线程。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:4:3","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#内存碎片整理大-key-是否阻塞"},{"categories":["Redis升级"],"content":" 手动内存整理 Memory Purge该命令只在使用 jemalloc 内存分配器下生效。 该命令清理内存脏页，和上述内存碎片整理功能管理的不是相同区域。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:5:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#手动内存整理-memory-purge"},{"categories":["Redis升级"],"content":" 结论Redis 内存碎片整理功能是通过 scan 命令渐进式地整理每次迭代到的 key，每次调用的时间复杂度为 O(1), 完整执行完一次内存碎片整理功能的时间复杂度为 O(n)。 内存碎片整理大 key 会将大 key 分多次处理，不会长时间阻塞主线程。 内存碎片整理功能的核心作用是降低内存碎片率，提高内存利用率以节省内存成本。 但内存整理功能在主线程中执行，会阻塞主线程而降低 Redis 的性能。 ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:6:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#结论"},{"categories":["Redis升级"],"content":" 参考资料Memory optimization | Redis redis/defrag.c at unstable · redis/redis · GitHub MEMORY PURGE | Redis ","date":"2023-04-19","objectID":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/:7:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis 内存碎片整理调研","uri":"/redis%E5%8D%87%E7%BA%A7_2_%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/#参考资料"},{"categories":["「算法第四版」"],"content":"「算法第四版」Union-Find 算法","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/"},{"categories":["「算法第四版」"],"content":" 动态连通性问题及其应用若整数对 (p, q) 是“相连”的，则： 自反性：p 和 p 是相连的； 对称性：如果 p 和 q 是相连的，那么 q 和 p 也是相连的； 传递性：如果 p 和 q 是相连的且 q 和 r 是相连的，那么 p 和 r 也是相连的。 当且仅当两个对象相连时它们才属于同一个等价类。 判断一对新的对象是否“相连”，这样的问题叫动态连通性问题。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#动态连通性问题及其应用"},{"categories":["「算法第四版」"],"content":" 网络在大型计算机网络中，输入的整数表示主机(触点)，整数对表示网络(连接)，同一网络中的主机属于同一等价类(连通分量)。 在社交网络中，整数可以表示社交网络中的人，整数对表示朋友关系。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:1:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#网络"},{"categories":["「算法第四版」"],"content":" 数学集合将每个整数看做属于不同的数学集合，每一个整数对则需要先判断是否在同一数学集合中。若不是，则将 p 所属集合与 q 所属集合归并到同一集合。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:1:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#数学集合"},{"categories":["「算法第四版」"],"content":" Union-Find 算法的 API public class UF UF(int N) 以整数标志 [0, N-1] 初始化 N 个触点 void union(int p, int q) 在 p 和 q 之间添加一条连接 int find(int p) p (0 \u003c= p \u003c= N-1) 所在的分量标识符 boolean connected(int p, int q) p 和 q 是否连通 int count() 连通分量的数量 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#union-find-算法的-api"},{"categories":["「算法第四版」"],"content":" Union-Find 算法的实现基本的 UF 算法实现见如下代码，union 与 find 的详细实现分别见 Quick-Find，Quick-Union，Weighted Quick-Union，Quick-Union with Path Compresson 的实现。 public class UF { private int[] id; private int count; public UF(int n) { count = n; id = new int[n]; for (int i = 0; i \u003c n; i++) id[i] = i; } public void union(int p, int q); public int find(int p); public boolean connected(int p, int q) { return find(p) == find(q); } public int count() { return count; } private void validate(int p) { int n = id.length; if (p \u003c 0 || p \u003e= n) { throw new IllegalArgumentException(\"index \" + p + \" is not between 0 and \" + (n-1)); } } public static void main(String[] args) { int n = StdIn.readInt(); UF uf = new UF(n); while (!StdIn.isEmpty()) { int p = StdIn.readInt(); int q = StdIn.readInt(); if (uf.find(p) == uf.find(q)) continue; uf.union(p, q); StdOut.println(p + \" \" + q); } StdOut.println(uf.count() + \" components\"); } } ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#union-find-算法的实现"},{"categories":["「算法第四版」"],"content":" Quick-Find public class QuickFindUF { private int[] id; // id[i] = component identifier of i private int count; // number of components public QuickFindUF(int n) { count = n; id = new int[n]; for (int i = 0; i \u003c n; i++) id[i] = i; } public void union(int p, int q) { validate(p); validate(q); int pID = id[p]; // needed for correctness int qID = id[q]; // to reduce the number of array accesses // p and q are already in the same component if (pID == qID) return; for (int i = 0; i \u003c id.length; i++) if (id[i] == pID) id[i] = qID; count--; } public int find(int p) { validate(p); return id[p]; } } Quick-Find 算法中，find 方法的时间复杂度为 O(1)，但 union 方法的时间复杂度为 O(n)。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:3:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#quick-find"},{"categories":["「算法第四版」"],"content":" Quick-Union public class QuickUnionUF { private int[] parent; // parent[i] = parent of i private int count; // number of components public QuickUnionUF(int n) { parent = new int[n]; count = n; for (int i = 0; i \u003c n; i++) { parent[i] = i; } } public void union(int p, int q) { int rootP = find(p); int rootQ = find(q); if (rootP == rootQ) return; parent[rootP] = rootQ; count--; } public int find(int p) { validate(p); while (p != parent[p]) p = parent[p]; return p; } } Quick-Union 算法中，h 表示树的高度，find 方法的时间复杂度为 O(h)，union 方法的时间复杂度为 2·O(h) + 1 = O(h)。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:3:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#quick-union"},{"categories":["「算法第四版」"],"content":" Weighted Quick-Union public class WeightedQuickUnionUF { private int[] parent; // parent[i] = parent of i private int[] size; // size[i] = number of elements in subtree rooted at i private int count; // number of components public WeightedQuickUnionUF(int n) { count = n; parent = new int[n]; size = new int[n]; for (int i = 0; i \u003c n; i++) { parent[i] = i; size[i] = 1; } } public void union(int p, int q) { int rootP = find(p); int rootQ = find(q); if (rootP == rootQ) return; // make smaller root point to larger one if (size[rootP] \u003c size[rootQ]) { parent[rootP] = rootQ; size[rootQ] += size[rootP]; } else { parent[rootQ] = rootP; size[rootP] += size[rootQ]; } count--; } public int find(int p) { validate(p); while (p != parent[p]) p = parent[p]; return p; } } 加权 Quick-Union 算法在最坏情况下，即归并的两个树大小总是相等，此时能够保证对数级别的性能 O(logN)。 加权 Quick-Union 算法能够在合理时间范围内处理大规模动态连通性问题。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:3:3","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#weighted-quick-union"},{"categories":["「算法第四版」"],"content":" Weighted Quick-Union with Path Compresson public class WeightedQuickUnionWithPathCompression { private final int[] parent; private final int[] size; private int count; WeightedQuickUnionWithPathCompression(int n) { parent = new int[n]; size = new int[n]; for (int i = 0; i \u003c n; i++) { parent[i] = i; size[i] = 1; } count = n; } public void union(int p, int q) { int rootP = find(p); int rootQ = find(q); if (rootP == rootQ) return; if (size[rootP] \u003c size[rootQ]) { parent[rootP] = rootQ; size[rootQ] += size[rootP]; } else { parent[rootQ] = rootP; size[rootP] += size[rootQ]; } count--; } public int find(int p) { validate(p); int root = p; while (root != parent[root]) { root = parent[root]; } // Path Compression while (parent[p] != root) { int temp = parent[p]; parent[p] = root; p = temp; } return root; } } 路经压缩的加权 Quick-Union 算法，find 方法能够得到几乎完全扁平化的树，使得算法的均摊成本接近 O(1)。 路经压缩的加权 Quick-Union 算法是本题的最优算法。 ","date":"2023-04-15","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/:3:4","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」Union-Find 算法","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_05_union-find%E7%AE%97%E6%B3%95/#weighted-quick-union-with-path-compresson"},{"categories":null,"content":"整理记录 Shell Script 语法","date":"2023-04-14","objectID":"/shell-script-%E6%95%B4%E7%90%86/","series":null,"tags":null,"title":"Shell Script 整理","uri":"/shell-script-%E6%95%B4%E7%90%86/"},{"categories":null,"content":" Shell 参数处理特殊字符 #!/bin/bash echo \"Starting program at $(date)\" # 1. $( CMD ) 运行 CMD 命令 echo \"Running program $0 with $# arguments with pid $$\" # 2. 见特殊字符表 for file in \"$@\"; do # 3. 见特殊字符表 grep foobar \"$file\" \u003e /dev/null 2\u003e /dev/null # 4. \"2\u003e /dev/null\" 把标准错误重定向到/dev/null if [[ $? -ne 0 ]]; then # 5. 见特殊字符表；在比较操作中使用双中括号 echo \"File $file does not have any foobar, adding one\" echo \"# foobar\" \u003e\u003e \"$file\" fi done ","date":"2023-04-14","objectID":"/shell-script-%E6%95%B4%E7%90%86/:1:0","series":null,"tags":null,"title":"Shell Script 整理","uri":"/shell-script-%E6%95%B4%E7%90%86/#shell-参数处理特殊字符"},{"categories":null,"content":" 特殊字符表 参数处理 说明 $0 Shell Script 名字 $# 参数个数 $$ 进程 PID $@ 所有参数 $? 上一条命令的返回码 ","date":"2023-04-14","objectID":"/shell-script-%E6%95%B4%E7%90%86/:1:1","series":null,"tags":null,"title":"Shell Script 整理","uri":"/shell-script-%E6%95%B4%E7%90%86/#特殊字符表"},{"categories":null,"content":" Test 命令的双中括号Differences Between Single and Double Brackets in Bash. ","date":"2023-04-14","objectID":"/shell-script-%E6%95%B4%E7%90%86/:1:2","series":null,"tags":null,"title":"Shell Script 整理","uri":"/shell-script-%E6%95%B4%E7%90%86/#test-命令的双中括号"},{"categories":null,"content":" Safe-bgsave 脚本整理 #!/bin/bash function help() # 1. 函数声明 { echo \"usage: safe-bgsave -t THRESHOLD -i INTERVAL -p PORT.\" echo \" safe-bgsave -t 20 -i 1 -p 7002\" exit } # success return 0; fail return 1. function safe_bgsave() { # check security local available=`free -g | grep Mem | awk '{print $7}'` # 2. awk 选取第 7 列 if [ ${available} -le ${THRESHOLD} ] then echo `date` \" Available memory: ${available} \u003c= threshold: ${THRESHOLD}. Do not process bgsave.\" \u003e\u003e ${LOG_PATH} 2\u003e\u00261 return 1 fi # bgsave local bgsave=`${REDIS_CLI} -p ${PORT} bgsave` echo `date` \" ${bgsave}.\" \u003e\u003e ${LOG_PATH} 2\u003e\u00261 # 3. 字符串拼接；\"2\u003e\u00261\" 将标准错误重定向到标准输出 sleep ${INTERVAL} local pid=`ps -ef | grep \"${PROCESS_NAME}\" | grep -v grep | awk '{print $2}'` while [ -n \"${pid}\" ] do available=`free -g | grep Mem | awk '{print $7}'` if [ ${available} -le ${THRESHOLD} ] then echo `date` \" bgsave failed. Available memory: ${available} \u003c= threshold: ${THRESHOLD}. Trying to kill process.\" \u003e\u003e ${LOG_PATH} 2\u003e\u00261 kill \"${pid}\" return 1 fi sleep ${INTERVAL} pid=`ps -ef | grep \"${PROCESS_NAME}\" | grep -v grep | awk '{print $2}'` done echo `date` \" bgsave success.\" \u003e\u003e ${LOG_PATH} 2\u003e\u00261 return 0 } # Begin [ $# -ne 6 ] \u0026\u0026 help # 4. 检查参数个数；调用 help 函数 while [ -n \"$1\" ] # 5. 参数赋值的写法 do case \"$1\" in -t) THRESHOLD=$2 shift 2 # 6. 将参数数组向左移动两位 ;; -i) INTERVAL=$2 shift 2 ;; -p) PORT=$2 shift 2 ;; *) help ;; esac done REDIS_CLI=\"redis-cli\" PROCESS_NAME=\"redis-rdb-bgsave\" LOG_PATH=\"/opt/data/redis/safe_bgsave.${PORT}.log\" safe_bgsave if [ $? -eq 1 ] then exit 1 fi exit 0 ","date":"2023-04-14","objectID":"/shell-script-%E6%95%B4%E7%90%86/:2:0","series":null,"tags":null,"title":"Shell Script 整理","uri":"/shell-script-%E6%95%B4%E7%90%86/#safe-bgsave-脚本整理"},{"categories":["「算法第四版」"],"content":"「算法第四版」算法分析","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/"},{"categories":["「算法第四版」"],"content":" 算法分析的方法 Observe some feature of the natural world, generally with precise measurements. Hypothesize a model that is consistent with the observations. Predict events using the hypothesis. Verify the predictions by making further observations. Validate by repeating until the hypothesis and observations agree. ","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#算法分析的方法"},{"categories":["「算法第四版」"],"content":" 算法运行时间实验程序执行速度的快慢通常取决于问题的规模。 通过观察代码初步预测程序的执行时间。 使用类似 DoublingTest 方法不断增加问题规模并计时，进入“预测——验证”循环。 public class DoublingTest { public static double timeTrial(int N) { // Time ThreeSum.count() for N random 6-digit ints. int MAX = 1000000; int[] a = new int[N]; for (int i = 0; i \u003c N; i++) a[i] = StdRandom.uniformInt(-MAX, MAX); Stopwatch timer = new Stopwatch(); int cnt = ThreeSum.count(a); return timer.elapsedTime(); } public static void main(String[] args) { // Print table of running times. for (int N = 250; true; N += N) { // Print time for problem size N. double time = timeTrial(N); StdOut.printf(\"%7d %5.1f\\n\", N, time); } } } 分析实验数据，得到其运行时间的数学模型。 ","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#算法运行时间实验"},{"categories":["「算法第四版」"],"content":" 运行时间的数学模型得到运行时间的数学模型步骤：（书：P114） 确定输入模型，定义问题规模 识别内循环 根据内循环中的操作确定成本模型 对于给定的输入，判断这些操作的执行频率 ","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#运行时间的数学模型"},{"categories":["「算法第四版」"],"content":" 增长数量级 描述 增长的数量级 典型代码 说明 举例 常数级别 1 a = b + c 普通语句 两个数相加 对数级别 logN 二分查找 二分策略 二分查找 线性级别 N 循环 循环 循环查找最大元素 线性对数级别 NlogN 归并排序 Merge.sort 和 快速排序 Quick.sort 归并排序，快速排序 归并排序，快速排序 平方级别 N^2 选择排序 Selection.sort 和 插入排序 Insertion.sort 双层循环 选择排序，插入排序 立方级别 N^3 ThreeSum 三层循环 三层循环 三层循环 指数级别 2^N 第六章 穷举查找 检查所有子集 ","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/:4:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#增长数量级"},{"categories":["「算法第四版」"],"content":" 倍率实验通过倍率实验能够简单有效地预测任意程序的性能并判断它们运行时间大致的增长数量级，但对比值没有极限的算法无效。 public class DoublingRatio { public static double timeTrial(int N) { // Time ThreeSum.count() for N random 6-digit ints. int MAX = 1000000; int[] a = new int[N]; for (int i = 0; i \u003c N; i++) a[i] = StdRandom.uniformInt(-MAX, MAX); Stopwatch timer = new Stopwatch(); int cnt = ThreeSum.count(a); return timer.elapsedTime(); } public static void main(String[] args) { double prev = timeTrial(125); for (int N = 250; true; N += N) { double time = timeTrial(N); StdOut.printf(\"%6d %7.1f \", N, time); StdOut.printf(\"%5.1f\\n\", time / prev); prev = time; } } } 在有性能问题的情况家应该考虑对编写过的所有程序进行倍率实验，以便能找到性能问题。 ","date":"2023-04-12","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/:5:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」算法分析","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_04_%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/#倍率实验"},{"categories":["「算法第四版」"],"content":"「算法第四版」背包、队列和栈","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/"},{"categories":["「算法第四版」"],"content":" 背包背包 API： 背包 public class Bag\u003cItem\u003e implements Iterable\u003cItem\u003e Bag() 创建一个背包 void add(Item item) 添加一个元素 boolean isEmpty() 背包是否为空 int size() 背包中元素数量 背包是一种不支持从中删除元素的集合数据类型——他的目的是帮助用例收集元素并迭代遍历所有收集到的元素。 ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#背包"},{"categories":["「算法第四版」"],"content":" 背包的链表实现 import java.util.Iterator; public class Bag\u003cItem\u003e implements Iterable\u003cItem\u003e { private Node first; private class Node { Item item; Node next; } public void add(Item item) { Node oldFirst = first; first = new Node(); first.item = item; first.next = oldFirst; } @Override public Iterator\u003cItem\u003e iterator() { return new ListIterator(); } private class ListIterator implements Iterator\u003cItem\u003e { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:1:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#背包的链表实现"},{"categories":["「算法第四版」"],"content":" 先进先出（FIFO）队列队列 API： 先进先出（FIFO）队列 public class Queue\u003cItem\u003e implements Interable\u003cItem\u003e Queue() 创建空队列 void enqueue(Item item) 添加一个元素 Item dequeue() 删除最早添加的元素 boolean isEmpty() 队列是否为空 int size() 队列中的元素数量 先进先出队列是一种基于先进先出（FIFO）策略的集合类型。 ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#先进先出fifo队列"},{"categories":["「算法第四版」"],"content":" 队列的实现 队列的链表实现 import java.util.Iterator; public class Queue\u003cItem\u003e implements Iterable\u003cItem\u003e { private Node first; private Node last; private int size; private class Node { Item item; Node next; } public boolean isEmpty() { return first == null; } public int size() { return size; } public void enqueue(Item item) { Node oldLast = last; last = new Node(); last.item = item; last.next = null; if (isEmpty()) { first = last; } else { oldLast.next = last; } size++; } public Item dequeue() { Item item = first.item; first = first.next; if (isEmpty()) { last = null; } size--; return item; } @Override public Iterator\u003cItem\u003e iterator() { return new ListIterator(); } private class ListIterator implements Iterator\u003cItem\u003e { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:2:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#队列的实现"},{"categories":["「算法第四版」"],"content":" 队列的实现 队列的链表实现 import java.util.Iterator; public class Queue implements Iterable { private Node first; private Node last; private int size; private class Node { Item item; Node next; } public boolean isEmpty() { return first == null; } public int size() { return size; } public void enqueue(Item item) { Node oldLast = last; last = new Node(); last.item = item; last.next = null; if (isEmpty()) { first = last; } else { oldLast.next = last; } size++; } public Item dequeue() { Item item = first.item; first = first.next; if (isEmpty()) { last = null; } size--; return item; } @Override public Iterator iterator() { return new ListIterator(); } private class ListIterator implements Iterator { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:2:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#队列的链表实现"},{"categories":["「算法第四版」"],"content":" 后进先出（LIFO）栈栈 API： public class Stack\u003cItem\u003e implements Iterable\u003cItem\u003e Stack() 创建一个空栈 void push() 添加一个元素 Item pop() 删除最近添加的元素 boolean isEmpty() 栈是否为空 int size() 栈中元素数量 ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#后进先出lifo栈"},{"categories":["「算法第四版」"],"content":" 栈的实现 栈的数组实现 import java.util.Iterator; public class ResizingArrayStack\u003cItem\u003e implements Iterable\u003cItem\u003e { private Item[] array = (Item[]) new Object[1]; private int size = 0; public boolean isEmpty() { return size == 0; } public int size() { return size; } public void push(Item item) { if (size == array.length) { resize(2 * array.length); } array[size++] = item; } public Item pop() { Item item = array[--size]; array[size] = null; if (size \u003e 0 \u0026\u0026 size == array.length / 4) { resize(array.length / 2); } return item; } private void resize(int length) { Item[] temp = (Item[]) new Object[length]; for (int i = 0; i \u003c size; i++) { temp[i] = array[i]; } array = temp; } @Override public Iterator\u003cItem\u003e iterator() { return new ReverseArrayIterator(); } private class ReverseArrayIterator implements Iterator\u003cItem\u003e { private int index = size; @Override public boolean hasNext() { return index \u003e 0; } @Override public Item next() { return array[--index]; } } } 栈的链表实现 import java.util.Iterator; public class Stack\u003cItem\u003e implements Iterable\u003cItem\u003e { private Node first; private int size; private class Node { Item item; Node next; } public boolean isEmpty() { return first == null; } public int size() { return size; } public void push(Item item) { Node oldFirst = first; first = new Node(); first.item = item; first.next = oldFirst; size++; } public Item pop() { Item item = first.item; first = first.next; size--; return item; } @Override public Iterator\u003cItem\u003e iterator() { return new ListIterator(); } private class ListIterator implements Iterator\u003cItem\u003e { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:3:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#栈的实现"},{"categories":["「算法第四版」"],"content":" 栈的实现 栈的数组实现 import java.util.Iterator; public class ResizingArrayStack implements Iterable { private Item[] array = (Item[]) new Object[1]; private int size = 0; public boolean isEmpty() { return size == 0; } public int size() { return size; } public void push(Item item) { if (size == array.length) { resize(2 * array.length); } array[size++] = item; } public Item pop() { Item item = array[--size]; array[size] = null; if (size \u003e 0 \u0026\u0026 size == array.length / 4) { resize(array.length / 2); } return item; } private void resize(int length) { Item[] temp = (Item[]) new Object[length]; for (int i = 0; i \u003c size; i++) { temp[i] = array[i]; } array = temp; } @Override public Iterator iterator() { return new ReverseArrayIterator(); } private class ReverseArrayIterator implements Iterator { private int index = size; @Override public boolean hasNext() { return index \u003e 0; } @Override public Item next() { return array[--index]; } } } 栈的链表实现 import java.util.Iterator; public class Stack implements Iterable { private Node first; private int size; private class Node { Item item; Node next; } public boolean isEmpty() { return first == null; } public int size() { return size; } public void push(Item item) { Node oldFirst = first; first = new Node(); first.item = item; first.next = oldFirst; size++; } public Item pop() { Item item = first.item; first = first.next; size--; return item; } @Override public Iterator iterator() { return new ListIterator(); } private class ListIterator implements Iterator { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:3:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#栈的数组实现"},{"categories":["「算法第四版」"],"content":" 栈的实现 栈的数组实现 import java.util.Iterator; public class ResizingArrayStack implements Iterable { private Item[] array = (Item[]) new Object[1]; private int size = 0; public boolean isEmpty() { return size == 0; } public int size() { return size; } public void push(Item item) { if (size == array.length) { resize(2 * array.length); } array[size++] = item; } public Item pop() { Item item = array[--size]; array[size] = null; if (size \u003e 0 \u0026\u0026 size == array.length / 4) { resize(array.length / 2); } return item; } private void resize(int length) { Item[] temp = (Item[]) new Object[length]; for (int i = 0; i \u003c size; i++) { temp[i] = array[i]; } array = temp; } @Override public Iterator iterator() { return new ReverseArrayIterator(); } private class ReverseArrayIterator implements Iterator { private int index = size; @Override public boolean hasNext() { return index \u003e 0; } @Override public Item next() { return array[--index]; } } } 栈的链表实现 import java.util.Iterator; public class Stack implements Iterable { private Node first; private int size; private class Node { Item item; Node next; } public boolean isEmpty() { return first == null; } public int size() { return size; } public void push(Item item) { Node oldFirst = first; first = new Node(); first.item = item; first.next = oldFirst; size++; } public Item pop() { Item item = first.item; first = first.next; size--; return item; } @Override public Iterator iterator() { return new ListIterator(); } private class ListIterator implements Iterator { private Node current = first; @Override public boolean hasNext() { return current != null; } @Override public Item next() { Item item = current.item; current = current.next; return item; } } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:3:1","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#栈的链表实现"},{"categories":["「算法第四版」"],"content":" 栈的应用Dijkstra 双栈算术表达式求值算法 public class Evaluate { public static void main(String[] args) { Stack\u003cString\u003e ops = new Stack\u003c\u003e(); Stack\u003cDouble\u003e vals = new Stack\u003c\u003e(); while (!StdIn.isEmpty()) { String s = StdIn.readString(); switch (s) { case \"(\" -\u003e { ; } case \"+\", \"-\", \"*\", \"/\", \"sqrt\" -\u003e ops.push(s); case \")\" -\u003e { String op = ops.pop(); double v = vals.pop(); v = switch (op) { case \"+\" -\u003e vals.pop() + v; case \"-\" -\u003e vals.pop() - v; case \"*\" -\u003e vals.pop() * v; case \"/\" -\u003e vals.pop() / v; case \"sqrt\" -\u003e Math.sqrt(v); default -\u003e v; }; vals.push(v); } default -\u003e vals.push(Double.parseDouble(s)); } } StdOut.println(vals.pop()); } } ","date":"2023-03-19","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/:3:2","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」背包、队列和栈","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_03_%E8%83%8C%E5%8C%85%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%88/#栈的应用"},{"categories":null,"content":"Volatile变量与线程安全","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/"},{"categories":null,"content":" 一个线程不安全的现象一个数组实现的环形缓冲区，变量 readPos 和 writePos 分别记录下一个读取的索引和下一个写入的索引。当缓冲区为空时，消费者会在数据存入缓冲区前等待。当缓冲区满时，生产者会等待将数据存入缓冲区。 public class RingBuffer\u003cItem\u003e { private final Item[] buffer; private int readPos; private int writePos; RingBuffer(int capacity) { this.buffer = (Item[]) new Object[capacity]; this.readPos = 0; this.writePos = 0; } public void write(Item item) { while (isFull()) ; buffer[writePos] = item; writePos = (writePos + 1) % buffer.length; } public Item read() { while (isEmpty()) ; Item item = buffer[readPos]; readPos = (readPos + 1) % buffer.length; return item; } private boolean isEmpty() { return readPos == writePos; } private boolean isFull() { return ((writePos + 1) % buffer.length) == readPos; } public static void main(String[] args) { RingBuffer\u003cInteger\u003e ringBuffer = new RingBuffer\u003c\u003e(10); Thread writer1 = new Thread(() -\u003e { for (int item = 0; item \u003c Integer.MAX_VALUE; item++) { ringBuffer.write(item); } }); writer1.start(); while (true) { StdOut.println(ringBuffer.read()); } } } 在运行此测试用例时发现两个线程都容易进入死循环。写入线程一直认为缓冲区是满的，消费线程一直认为缓冲区是空的。经过排查，此现象是 readPos 和 writePos 变量不一致导致的。 在写入线程中，writePos 变量只会被写入线程修改，因此该变量对于写入线程来说始终是最新值。而写入线程调用 isFull 方法的 readPos 变量会被读取线程修改，导致写入线程中 readPos 变量是旧数据。 在读取线程中，readPos 变量只会被读取线程修改，因此该变量对于读取线程来说始终是最新值。而读取线程调用 isEmpty 方法的 writePos 变量会被写入线程修改，导致读取线程中 writePos 变量是旧数据。 ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:1:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#一个线程不安全的现象"},{"categories":null,"content":" 解决方案将 readPos 和 writePos 改为 volatile 变量，在这个场景中能够保证这两个变量的线程安全。 那么 volatile 变量在此场景中是如何保证线程安全的呢？ ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:2:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#解决方案"},{"categories":null,"content":" volatile 变量机制","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:3:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#volatile-变量机制"},{"categories":null,"content":" 可见行保证对于非 volatile 变量，JVM 不会保证线程修改变量会被立即从 CPU 缓存中回写到主内存中。使得另一个线程可能会从主内存读取到该变量的旧值。 对于 volatile 变量，JVM 会保证线程每次都会从主内存中读取该变量。并且对该变量的修改会被立即回写到主内存。此时其余所有线程都会看到该变量的最新值。 ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:3:1","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#可见行保证"},{"categories":null,"content":" happens-before 保证happens-before 保证会对指令重排序进行限制。 对 volatile 变量进行写入操作之前的所有指令不会因指令重排序导致这些指令在写入操作的后面； 对 volatile 变量进行读取操作之后的所有指令不会因指令重排序导致这些指令在写入操作的之前。 即本应在 volatile 变量读取与写入操作之间的指令，不会因为指令重排序导致这些指令在变量读取与写入操作之外。 ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:3:2","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#happens-before-保证"},{"categories":null,"content":" volatile 变量何时是线程安全的？在以下两个场景，volatile 变量是线程安全的： 当只有一个线程向 volatile 变量写入，其余多个线程仅读取该变量时，总会读取最新的数据，此时是线程安全的； 当多个线程向 volatile 变量写入并且对变量的操作是原子操作（被写入的新值不依赖旧值），此时是线程安全的。 ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:4:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#volatile-变量何时是线程安全的"},{"categories":null,"content":" 一个 volitile 变量例子 public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:5:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#一个-volitile-变量例子"},{"categories":null,"content":" 参考资料Concurrency in Java: “synchronized” and “volatile” keywords Volatile Variables and Thread Safety ","date":"2023-03-11","objectID":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/:6:0","series":null,"tags":null,"title":"Volatile变量与线程安全","uri":"/volatile%E5%8F%98%E9%87%8F%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/#参考资料"},{"categories":["Redis升级"],"content":"通过分析 Redis 异步删除源码，判断异步删除能否解决大 Key 过期阻塞主线程的问题。","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/"},{"categories":["Redis升级"],"content":"自 Redis 4 版本引入了异步删除方法 unlink，官方对该接口的解释： “This command is very similar to DEL: it removes the specified keys. Just like DEL a key is ignored if it does not exist. However the command performs the actual memory reclaiming in a different thread, so it is not blocking, while DEL is. This is where the command name comes from: the command just unlinks the keys from the keyspace. The actual removal will happen later asynchronously.” 可知 unlink 与 del 用法相同，只不过内存回收在另一个不同线程中，内存回收操作在 unlink 方法调用结束之后，因此是非阻塞方法。 ","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:0:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#"},{"categories":["Redis升级"],"content":" 源码分析","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:1:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#源码分析"},{"categories":["Redis升级"],"content":" 异步删除流程同步删除与异步删除的方法入口分别为 delCommand 方法与 unlinkCommand 方法。 void delCommand(client *c) { delGenericCommand(c,server.lazyfree_lazy_user_del); } void unlinkCommand(client *c) { delGenericCommand(c,1); } 这两个方法都调用 delGenericCommand 方法，server.lazyfree_lazy_user_del 可通过配置文件配置，配置后可以使 del 命令与 unlink 命令完全相同。 /* This command implements DEL and LAZYDEL. */ void delGenericCommand(client *c, int lazy) { int numdel = 0, j; for (j = 1; j \u003c c-\u003eargc; j++) { expireIfNeeded(c-\u003edb,c-\u003eargv[j],0); // 判断传入的 lazy 值选择异步删除或同步删除 int deleted = lazy ? dbAsyncDelete(c-\u003edb,c-\u003eargv[j]) : dbSyncDelete(c-\u003edb,c-\u003eargv[j]); if (deleted) { signalModifiedKey(c,c-\u003edb,c-\u003eargv[j]); notifyKeyspaceEvent(NOTIFY_GENERIC, \"del\",c-\u003eargv[j],c-\u003edb-\u003eid); server.dirty++; numdel++; } } addReplyLongLong(c,numdel); } delGenericCommand 方法判断传入的 lazy 参数值决定异步删除或者同步删除。 /* Delete a key, value, and associated expiration entry if any, from the DB */ int dbSyncDelete(redisDb *db, robj *key) { return dbGenericDelete(db, key, 0); } /* Delete a key, value, and associated expiration entry if any, from the DB. If * the value consists of many allocations, it may be freed asynchronously. */ int dbAsyncDelete(redisDb *db, robj *key) { return dbGenericDelete(db, key, 1); } 同步删除和异步删除都是调用 dbGenericDelete 方法，仅传入的 async 参数不同。 /* Helper for sync and async delete. */ static int dbGenericDelete(redisDb *db, robj *key, int async) { /* Deleting an entry from the expires dict will not free the sds of * the key, because it is shared with the main dictionary. */ // 删除 expires 字典中该 key，但不会删除 SDS 结构，因为该 SDS 在 dict 字典中被共享。 if (dictSize(db-\u003eexpires) \u003e 0) dictDelete(db-\u003eexpires,key-\u003eptr); // 数据库字典中移除 key，不释放内存。 dictEntry *de = dictUnlink(db-\u003edict,key-\u003eptr); if (de) { robj *val = dictGetVal(de); /* Tells the module that the key has been unlinked from the database. */ moduleNotifyKeyUnlink(key,val,db-\u003eid); /* We want to try to unblock any client using a blocking XREADGROUP */ if (val-\u003etype == OBJ_STREAM) signalKeyAsReady(db,key,val-\u003etype); if (async) { // 异步释放内存 freeObjAsync(key, val, db-\u003eid); dictSetVal(db-\u003edict, de, NULL); } if (server.cluster_enabled) slotToKeyDelEntry(de, db); // 释放内存 dictFreeUnlinkedEntry(db-\u003edict,de); return 1; } else { return 0; } } /* You need to call this function to really free the entry after a call * to dictUnlink(). It's safe to call this function with 'he' = NULL. */ void dictFreeUnlinkedEntry(dict *d, dictEntry *he) { if (he == NULL) return; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); } dbGenericDelete 方法首先将 key 在 expires 字典中删除并释放内存，再在 dict 字典中移除该 key，但此时不释放内存。 通过 async 参数判断是否需要异步释放内存，若需要则会调用 freeObjAsync 方法进行异步释放内存，若不需要异步释放内存，则在 dictFreeUnlinkedEntry 方法中直接释放。 若进入 freeObjAsync 方法但不满足异步释放条件（在 freeObjAsync 方法中），也会在 dictFreeUnlinkedEntry 方法中直接释放。 /* If there are enough allocations to free the value object asynchronously, it * may be put into a lazy free list instead of being freed synchronously. The * lazy free list will be reclaimed in a different bio.c thread. If the value is * composed of a few allocations, to free in a lazy way is actually just * slower... So under a certain limit we just free the object synchronously. */ #define LAZYFREE_THRESHOLD 64 /* Free an object, if the object is huge enough, free it in async way. */ void freeObjAsync(robj *key, robj *obj, int dbid) { // 计算异步删除阈值 size_t free_effort = lazyfreeGetFreeEffort(key,obj,dbid); /* Note that if the object is shared, to reclaim it now it is not * possible. This rarely happens, however sometimes the implementation * of parts of the Redis core may call incrRefCount() to protect * objects, and then call dbDelete(). */ if (free_effort \u003e LAZYFREE_THRESHOLD \u0026\u0026 obj-\u003erefcount == 1) { atomicIncr(lazyfree_objects,1); // 任务超过异步删除阈值，创建异步删除任务 bioCreateLazyFreeJob(lazyfreeFreeObject,1,obj); } else { decrRefCount(obj); } } 重点看 freeObjAsync 方法，先计算该 key 的异步删除阈值，若大于阈值 64，则为该 key 创建异步删除任务。 void bioCreateLazyFreeJob(lazy_free_fn free_fn, int arg_count, ...) { va_list valist; /* Allocate memory for the job structure and all required * a","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:1:1","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#异步删除流程"},{"categories":["Redis升级"],"content":" 惰性删除与异步删除Redis 惰性删除策略是否采用异步删除策略？ 在惰性删除中，Redis 在操作 Key 时会先判断该 Key 是否过期，若过期则会删除该 Key。 /* This function is called when we are going to perform some operation * in a given key, but such key may be already logically expired even if * it still exists in the database. The main way this function is called * is via lookupKey*() family of functions. * * The behavior of the function depends on the replication role of the * instance, because by default replicas do not delete expired keys. They * wait for DELs from the master for consistency matters. However even * replicas will try to have a coherent return value for the function, * so that read commands executed in the replica side will be able to * behave like if the key is expired even if still present (because the * master has yet to propagate the DEL). * * In masters as a side effect of finding a key which is expired, such * key will be evicted from the database. Also this may trigger the * propagation of a DEL/UNLINK command in AOF / replication stream. * * On replicas, this function does not delete expired keys by default, but * it still returns 1 if the key is logically expired. To force deletion * of logically expired keys even on replicas, use the EXPIRE_FORCE_DELETE_EXPIRED * flag. Note though that if the current client is executing * replicated commands from the master, keys are never considered expired. * * On the other hand, if you just want expiration check, but need to avoid * the actual key deletion and propagation of the deletion, use the * EXPIRE_AVOID_DELETE_EXPIRED flag. * * The return value of the function is 0 if the key is still valid, * otherwise the function returns 1 if the key is expired. */ int expireIfNeeded(redisDb *db, robj *key, int flags) { if (!keyIsExpired(db,key)) return 0; /* If we are running in the context of a replica, instead of * evicting the expired key from the database, we return ASAP: * the replica key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. The * exception is when write operations are performed on writable * replicas. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. * * When replicating commands from the master, keys are never considered * expired. */ if (server.masterhost != NULL) { if (server.current_client == server.master) return 0; if (!(flags \u0026 EXPIRE_FORCE_DELETE_EXPIRED)) return 1; } /* In some cases we're explicitly instructed to return an indication of a * missing key without actually deleting it, even on masters. */ if (flags \u0026 EXPIRE_AVOID_DELETE_EXPIRED) return 1; /* If clients are paused, we keep the current dataset constant, * but return to the client what we believe is the right state. Typically, * at the end of the pause we will properly expire the key OR we will * have failed over and the new primary will send us the expire. */ if (checkClientPauseTimeoutAndReturnIfPaused()) return 1; /* Delete the key */ // 删除 key deleteExpiredKeyAndPropagate(db,key); return 1; } expireIfNeeded 方法会调用 deleteExpiredKeyAndPropagate 方法删除 key。 删除 key 时会读取 server.lazyfree_lazy_expire 配置决定删除策略。server.lazyfree_lazy_expire 可在配置文件中配置，配置后惰性删除将采用异步删除策略。 /* Delete the specified expired key and propagate expire. */ void deleteExpiredKeyAndPropagate(redisDb *db, robj *keyobj) { mstime_t expire_latency; latencyStartMonitor(expire_latency); if (server.lazyfree_lazy_expire) // 采用异步删除策略 dbAsyncDelete(db,keyobj); else dbSyncDelete(db,keyobj); latencyEndMonitor(expire_latency); latencyAddSampleIfNeeded(\"expire-del\",expire_latency); notifyKeyspaceEvent(NOTIFY_EXPIRED,\"expired\",keyobj,db-\u003eid); signalModifiedKey(NULL, db, keyobj); propagateDeletion(db,keyobj,server.lazyfree_lazy_expire); server.stat_expiredkeys++; } 结论：Redis 惰性删除在配置后可采用异步删除策略。 ","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:1:2","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#惰性删除与异步删除"},{"categories":["Redis升级"],"content":" 定时删除与异步删除定时任务 serverCron 方法最终会调用 activeExpireCycleTryExpire 方法，该方法仍会调用 deleteExpiredKeyAndPropagate 方法。 /* Helper function for the activeExpireCycle() function. * This function will try to expire the key that is stored in the hash table * entry 'de' of the 'expires' hash table of a Redis database. * * If the key is found to be expired, it is removed from the database and * 1 is returned. Otherwise no operation is performed and 0 is returned. * * When a key is expired, server.stat_expiredkeys is incremented. * * The parameter 'now' is the current time in milliseconds as is passed * to the function to avoid too many gettimeofday() syscalls. */ int activeExpireCycleTryExpire(redisDb *db, dictEntry *de, long long now) { long long t = dictGetSignedIntegerVal(de); if (now \u003e t) { sds key = dictGetKey(de); robj *keyobj = createStringObject(key,sdslen(key)); // 删除 key deleteExpiredKeyAndPropagate(db,keyobj); decrRefCount(keyobj); return 1; } else { return 0; } } 结论：Redis 定时删除在配置后可采用异步删除策略。 ","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:1:3","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#定时删除与异步删除"},{"categories":["Redis升级"],"content":" 结论异步删除策略能够在删除大 Key 时避免主线程阻塞，惰性删除与定时删除在配置后均可采用异步删除策略，因此异步删除能够解决大 Key 过期引起的主线程阻塞问题。 ","date":"2023-03-04","objectID":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/:2:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis异步删除解决大Key过期阻塞问题可行性分析","uri":"/redis%E5%8D%87%E7%BA%A7_1_%E5%BC%82%E6%AD%A5%E5%88%A0%E9%99%A4/#结论"},{"categories":["Redis升级"],"content":"记录Redis升级流程。","date":"2023-03-03","objectID":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis升级——开篇","uri":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/"},{"categories":["Redis升级"],"content":" 现版本存在的问题目前在生产环境中部署的旧版本Redis存在的问题： 大 key 过期删除引发集群节点阻塞失去响应不可用； 内存碎片高，内存使用率低； 运维时，手动主从切换总会产生复制风暴问题，主从无法同步； bgsave 内存消耗较高，有 OOM 风险。 ","date":"2023-03-03","objectID":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/:1:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis升级——开篇","uri":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/#现版本存在的问题"},{"categories":["Redis升级"],"content":" 推进版本升级由于以上原因，开始推进 Redis 版本升级。 版本升级工作流程： 通过文档与源码，调研 Redis 新特性； 客户端兼容性改造； 功能测试、性能测试和稳定性测试； 开发配套监控和运维工具； 推进上线。 ","date":"2023-03-03","objectID":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/:2:0","series":["Redis升级笔记"],"tags":["Redis升级"],"title":"Redis升级——开篇","uri":"/redis%E5%8D%87%E7%BA%A7_0_%E5%BC%80%E7%AF%87/#推进版本升级"},{"categories":["「算法第四版」"],"content":"「算法第四版」欧几里得算法求最大公因数","date":"2023-02-27","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」欧几里得算法求最大公因数","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/"},{"categories":["「算法第四版」"],"content":" 自然语言描述计算两个非负整数 p 和 q 的最大公约数：若 q 是 0，则最大公约数为 p。否则，将 p 除以 q 得到余数 r，p 和 q 的最大公约数即为 q 和 r 的最大公约数。 ","date":"2023-02-27","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」欧几里得算法求最大公因数","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/#自然语言描述"},{"categories":["「算法第四版」"],"content":" 递归写法 public class Euclid { public static int gcd(int p, int q) { if (q == 0) return p; int r = p % q; return gcd(q, r); } } ","date":"2023-02-27","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」欧几里得算法求最大公因数","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/#递归写法"},{"categories":["「算法第四版」"],"content":" 循环写法 public class Euclid { public static int gcd(int p, int q) { if (q == 0) return p; while (q != 0) { int r = p % q; p = q; q = r; } return p; } } ","date":"2023-02-27","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」欧几里得算法求最大公因数","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_02_%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%9C%80%E5%A4%A7%E5%85%AC%E5%9B%A0%E6%95%B0/#循环写法"},{"categories":["「算法第四版」"],"content":"「算法第四版」二分查找","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"categories":["「算法第四版」"],"content":" 前提条件查找的数组是有序的。 ","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#前提条件"},{"categories":["「算法第四版」"],"content":" 递归写法 public class BinarySearch { public static int rank(int key, int[] a) { return rank(key, a, 0, a.length - 1); } public static int rank(int key, int[] a, int lo, int hi) { if (lo \u003e hi) return -1; int mid = lo + (hi - lo) / 2; if (key \u003c a[mid]) return rank(key, a, lo, hi - 1); else if (key \u003e a[mid]) return rank(key, a, lo + 1, hi); else return mid; } } ","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:2:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#递归写法"},{"categories":["「算法第四版」"],"content":" 循环写法 public class BinarySearch { public static int rank(int key, int[] a) { int lo = 0; int hi = a.length - 1; while (lo \u003c hi) { int mid = lo + (hi - lo) / 2; if (key \u003c a[mid]) hi = lo - 1; else if (key \u003e a[mid]) lo = hi + 1; else return mid; } return -1; } } ","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:3:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#循环写法"},{"categories":["「算法第四版」"],"content":" 二分查找 key 的最小索引 public class BinarySearch { public static int rank(int key, int[] a) { return rank(key, a, 0, a.length - 1); } public static int rank(int[] array, int key, int lo, int hi) { while (lo \u003c= hi) { int mid = lo + ((hi - lo) \u003e\u003e 1); if (key \u003c= array[mid]) { hi = mid - 1; } else { lo = mid + 1; } } if (lo == array.length) return -1; return array[lo] == key ? lo : -1; } } ","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:4:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#二分查找-key-的最小索引"},{"categories":["「算法第四版」"],"content":" 二分查找极小(大)值 public class BinarySearch { public static int partialMin(int[] array) { assert array != null \u0026\u0026 array.length \u003e 0; int lo = 0; int hi = array.length - 1; while (lo \u003c= hi) { int mid = lo + ((hi - lo) \u003e\u003e 1); if (mid == 0 || mid == array.length - 1) break; if (array[mid] \u003c array[mid - 1] \u0026\u0026 array[mid] \u003c array[mid + 1]) { return mid; } else if (array[mid - 1] \u003c= array[mid + 1]) { hi = mid - 1; } else { lo = mid + 1; } } return -1; } } ","date":"2023-02-26","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/:5:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」二分查找","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_01_%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/#二分查找极小大值"},{"categories":["「算法第四版」"],"content":"「算法第四版」阅读开篇","date":"2023-02-25","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_00_%E9%98%85%E8%AF%BB%E5%BC%80%E7%AF%87/","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」阅读开篇","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_00_%E9%98%85%E8%AF%BB%E5%BC%80%E7%AF%87/"},{"categories":["「算法第四版」"],"content":" 本系列文章作用2023 年计划将「算法第四版」认真阅读一遍，在博客中整理常用的算法，把书读薄，时常复习，提高编码水平。 习题仓库：https://github.com/Nanciico/algs4 加油！ ","date":"2023-02-25","objectID":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_00_%E9%98%85%E8%AF%BB%E5%BC%80%E7%AF%87/:1:0","series":["「算法第四版」阅读笔记"],"tags":["「算法第四版」"],"title":"「算法第四版」阅读开篇","uri":"/%E7%AE%97%E6%B3%95%E7%AC%AC%E5%9B%9B%E7%89%88_00_%E9%98%85%E8%AF%BB%E5%BC%80%E7%AF%87/#本系列文章作用"},{"categories":null,"content":" 关于我 姓名: Shuyang 职业: 后端程序员，负责 Redis 相关工作 ","date":"2022-10-13","objectID":"/about/:1:0","series":null,"tags":null,"title":"关于","uri":"/about/#关于我"}]